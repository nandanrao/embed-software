{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "size = 20000000\n",
    "\n",
    "embeddings = np.ones((size, 100))\n",
    "\n",
    "with open('./ss/ss_sentence_embeds.txt', 'r') as f:\n",
    "    j = 0\n",
    "    for i,l in enumerate(f):\n",
    "        if i%2 == 1:\n",
    "            a = np.array([float(n) for n in l.strip().split()])\n",
    "            embeddings[j,] = a\n",
    "            j += 1     \n",
    "        if j == size:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import linecache\n",
    "\n",
    "def get_sentence(i):\n",
    "    return linecache.getline('./prepared-readmes/by_sentence.txt', i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors()\n",
    "nn.fit(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "neighbors = nn.kneighbors(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2832737, 15625170,  2904240,  4870626,  8380282])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream stream node js\n",
      "\n",
      "Simple write stream that facilitates writing to MongoDB This module requires nodejs v4 or above\n",
      "\n",
      "nodejs simple fft is module that is quick wrapper for module\n",
      "\n",
      "That way it can be used like any other node stream\n",
      "\n",
      "That way it can be used like any other node stream\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in neighbors[1][4]:\n",
    "    print(get_sentence(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "with open('./ss/eye-vectors.txt', 'r') as f:\n",
    "    foo = [l.strip().split(' ') for i,l in enumerate(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "vecs = [np.array([float(n) for n in s]) for i,s in enumerate(foo[3:]) if i%2 == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.11286908,  0.59490071,  0.46092046,  0.89119703],\n",
       "       [ 1.11286908,  0.        ,  1.10232584,  1.09617264,  1.02196769],\n",
       "       [ 0.59490071,  1.10232584,  0.        ,  0.73975893,  1.01725889],\n",
       "       [ 0.46092046,  1.09617264,  0.73975893,  0.        ,  0.98335862],\n",
       "       [ 0.89119703,  1.02196769,  1.01725889,  0.98335862,  0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import pdist,squareform\n",
    "\n",
    "squareform(pdist(np.array(vecs), 'cosine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import strip_accents_ascii, strip_tags\n",
    "\n",
    "headlines = re.compile(r\"#+\\s*[^\\n]+\\n\")\n",
    "md_links = re.compile('\\[[^\\]]+\\]\\([^\\)]+\\)')\n",
    "sentance = re.compile(r\"\\.\\s+\")\n",
    "links = re.compile(r\"https?://[^\\s]+\")\n",
    "code_ticks = re.compile(r\"``?`?[^`]+``?`?\")\n",
    "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "tokenizer = lambda doc: token_pattern.findall(doc)\n",
    "underscore = re.compile(r\"\\w*_\\w*\")\n",
    "space = re.compile(r'\\s+')\n",
    "\n",
    "def preprocessor(s):\n",
    "\n",
    "    # Capitalization won't help us\n",
    "    s = s.lower()\n",
    "\n",
    "    # Remove code and markdown headlines\n",
    "    s = re.sub(code_ticks, '', s)    \n",
    "    s = re.sub(headlines, '', s)\n",
    "    s = re.sub(md_links, '', s)\n",
    "    s = re.sub(links, '', s)\n",
    "\n",
    "    # ASCII our text and remove html tags\n",
    "    s = strip_accents_ascii(s)\n",
    "    s = strip_tags(s)\n",
    "\n",
    "    # Underscores imply variable names, which are\n",
    "    # never useful. Get rid of anything in camelcase? \n",
    "    s = re.sub(underscore, '', s)\n",
    "\n",
    "\n",
    "    # Split on sentances, tokenize within the sentance, then replace \n",
    "    # sentance with \\t separator for starspace/fasttext\n",
    "    s = [i for i in sentance.split(s)]\n",
    "    s = [' '.join(tokenizer(i)) for i in s]\n",
    "    s = '\\t'.join([i for i in s if i])\n",
    "\n",
    "    # Get rid of useless little readmes\n",
    "    if len(space.split(s)) < 4:\n",
    "        return None\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this repo aims at reproducing the results of vqa from the following paper modulating early visual processing by language the code was equally developed by florian strub university of lille and harm de vries university of montreal the project is part of the chistera iglu project', 'based on condtional batch normalization technique', 'in few words resnet pipeline is altered by conditioning the batch normalization parameters on the question', 'it differs from classic approach that mainly focus on developing new attention mechanism', 'our code has internal dependencies called submodules', 'to properly clone the repository please use the following git command the code works on both python and', 'it relies on the tensorflow python api', 'it requires the following python packages in the following we assume that the following file folder architecture is respected to complete the git clone file arhictecture you can do of course one is free to change this file architecture vqa relies on two dataset vqav1 vqav2 note that we ran all lour experiments on vqav1 but the code is compatible with vqav2 dataset', 'to do so change the year 2014 to 2017 in this tutorial', 'to download the vqa dataset please use the script scripts sh pwd to come to launch the experiments in the local directory you first have to set the python path note that you can also directly execute the experiments in the source folder', 'before starting the training one needs to create dictionary you do not need to extract image feature for vqa cbn', 'yet this code does support any kind of image features as input', 'following the original papers we are going to extract fc8 features from the coco images by using vgg 16 network', 'first you need to download the resnet 152 pretrained network provided by them use the following scripts src vqa py', 'to create the vqa dictionary you need to use the python script vqa src vqa py', 'our model use glove vectors pre computed word embedding to perform well', 'to create the glove dictionary you first need to download the original glove file and the you need to use the pythn script guesswhat src guesswhat py', 'to train the network you need to select configure the kind of neural architecure you want', 'to do so you have update the file config vqa config json once the config file is set you can launch the training step after training we obtained the following results tbd when start python script have the following message importerror no module named generic iterator or equivalent module', 'it is likely that your python path is not correctly set', 'add the src folder to your python path pythonpath src sequel team mila team']\n",
      "['as part of the implementation series of our motivation is to accelerate or sometimes delay research in the ai community by promoting open source projects', 'to this end we implement state of the art research papers and publicly share them with concise reports', 'please visit our for other projects', 'this project is implemented by and the codes have been reviewed by before being published', 'this project is implementation of semi supervised learning generative adversarial networks proposed in the paper', 'the intuition is exploiting the samples generated by gan generators to boost the performance of image classification tasks by improving generalization', 'in sum the main idea is training network playing both the roles of classifier performing image classification task as well as discriminator trained to distinguish generated samples produced by generator from the real data', 'to be more specific the discriminator classifier takes an image as input and classified it into classes where is the number of classes of classification task', 'true samples are classified into the first classes and generated samples are classified into the th class as shown in the figure below', 'the loss of this multi task learning framework can be decomposed into the supervised loss and the gan loss of discriminator during the training phase we jointly minimize the total loss obtained by simply combining the two losses together', 'the implemented model is trained and tested on three publicly available datasets and', 'note that this implementation only follows the main idea of the original paper while differing lot in implementation details such as model architectures hyperparameters applied optimizer etc', 'also some useful training tricks applied to this implementation are stated at the end of this readme', 'this code is still being developed and subject to change', 'python or python download datasets with train models with downloaded datasets test models with saved checkpoints the should be like train and test your own datasets create directory store your data as an h5py file datasets data hy and each data point contains image has shape where is the number of channels grayscale images color images label represented as an one hot vector maintain list datasets id txt listing ids of all data points modify trainer py including args etc', 'finally train and test models generated samples 100th epochs first 40 epochs generated samples 100th epochs first 160 epochs generated samples 1000th epochs first 200 epochs the supervised loss the loss of discriminator total loss the loss of generator classification accuracy the supervised loss the loss of discriminator total loss the loss of generator classification accuracy the supervised loss the loss of discriminator total loss the loss of generator classification accuracy to avoid the fast convergence of the discriminator network the generator network is updated more frequently', 'higher learning rate is applied to the training of the generator', 'one sided label smoothing is applied to the positive labels', 'gradient clipping trick is applied to stablize training reconstruction loss with an annealed weight is applied as an auxiliary loss to help the generator get rid of the initial local minimum', 'utilize optimizer with higher momentum', 'please refer to the codes for more details', 'by springenberg by odena by dai et', 'al my implementation of in tensorflow the architecture diagram is modified from the one drawn in part of codes is from an unpublished project with']\n",
      "['references farhan tariq zaman shabbir khan', 'efficient approximation algorithms for strings kernel based sequence classification nips 2017 this implements new approximation based kernel algorithms for strings see references', 'data sources ding dubchak music genre ismir contest artist20 installation download source code folder to your desired directory and make sure environment variable for java is set cd source code javac main java this will produce executable class files for string kernel computations main class computes mismatch kernel matrices usage this function takes text file with sequences and output text file with kernel matrix', 'to compute mismatch kernel for sequences with alphabet size 1024 java main music genre txt 1000 1024 this will create kernel k8 m2 txt file with kernel matrix string kernels are called with the following parameters java main where is the file with sequence data one sequence per line line should end with line feed with sequence elements separated by space all sequence elements are assumed to be in the range', 'see datasets folder for an example of the sequence file format', 'are corresponding kernel parameters', 'see references and help for particular function for details is the size of the alphabet', 'output kernel matrix is written into kernel txt file', 'authors muhammad farhan 14030031 lums edu pk imdad ullah khan imdad khan lums edu pk']\n",
      "['author note please cite the following papers if you use the tool developed in this package', 'unified approach for learning the parameters of sum product networks by', 'zhao', 'poupart and', 'gordon nips 2016', 'collapsed variational inference for sum product networks by', 'zhao', 'adel', 'gordon and', 'amos icml 2016', 'linear time computation of moments in sum product networks by', 'zhao and', 'gordon nips 2017', 'required lib boost 55 cmake 80 the software is written in 11 for the purpose of parameter learning in sum product networks', 'it supports batch learning online learning as well as streaming learning', 'this software implements the following learning algorithms for spns', 'projected gradient descent', 'exponentiated gradient method', 'sequential monomial approximation zhao et al nips 2016', 'concave convex procedure expectation maximization zhao et al nips 2016', 'collapsed variational inference zhao et al icml 2016', 'online bayesian moment matching rashwan et al aistats 2016', 'assumed density filtering zhao et al nips 2017 usage', 'batch cpp online cpp and cpp should be the starting source files in order to understand the package', 'all the code about network structures is implemented in spnnode cpp and spnetwork cpp', 'learning algorithms under different learning scenarios batch online and streaming are implemented separately in the corresponding cpp files']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pytorch implementation of nips 2017 paper modulating early visual processing by language link the authors present novel approach to incorporate language information into extracting visual features by conditioning the batch normalization parameters on the language', 'they apply conditional batch normalization cbn to pre trained resnet and show that this significantly improves performance on visual question answering tasks', 'this repository is compatible with python', 'follow instructions outlined on for installing pytorch python2', 'the python packages required are which can be installed using pip', 'to download the vqa dataset please use the script scripts sh pwd detailed instructions for processing data are provided by guesswhatgame vqa to create the vqa dictionary use the script py', 'to create the glove dictionary download the original glove file and run the script py', 'to train the network set the required parameters in and run the script main py', 'if you find this code useful please consider citing the original work by authors']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "repos = [\n",
    "    'GuessWhatGame/vqa',\n",
    "    'gitlimlab/SSGAN-Tensorflow',\n",
    "    'mufarhan/sequence_class_NIPS_2017',\n",
    "    'KeiraZhao/SPN',\n",
    "    'ap229997/Conditional-Batch-Norm'\n",
    "]\n",
    "\n",
    "repo = repos[3]\n",
    "\n",
    "def get_readme(repo, attempts = 0):\n",
    "    filenames = [ 'README.md', 'readme.md']\n",
    "    try: \n",
    "        f = filenames[attempts]\n",
    "    except IndexError:\n",
    "        return None\n",
    "    r = requests.get('https://raw.githubusercontent.com/{}/master/{}'.format(repo, f))\n",
    "    if r.status_code == 404:\n",
    "        return get_readme(repo, attempts + 1)\n",
    "    return preprocessor(r.text).split('\\t')\n",
    "\n",
    "for repo in repos:\n",
    "    print(get_readme(repo))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
