{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install -U -q gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedLineDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "by_repo = LineSentence('./prepared-readmes/by_repo_no_sentence.txt')\n",
    "by_repo_doc = TaggedLineDocument('./prepared-readmes/by_repo_no_sentence.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "d2v = Doc2Vec(vector_size=100, min_count=20, window=10, epochs=5, workers=7, dbow_words=1)\n",
    "d2v.build_vocab(by_repo_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "d2v.train(by_repo_doc, total_examples=d2v.corpus_count, epochs=d2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.41102515, 0.03342422, 0.03764876, 0.06420119],\n",
       "       [0.41102515, 0.        , 0.37910537, 0.39696009, 0.42604322],\n",
       "       [0.03342422, 0.37910537, 0.        , 0.0458939 , 0.08013899],\n",
       "       [0.03764876, 0.39696009, 0.0458939 , 0.        , 0.0745646 ],\n",
       "       [0.06420119, 0.42604322, 0.08013899, 0.0745646 , 0.        ]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./ss/eye.txt', 'r') as f:\n",
    "    foo = [l.strip().split(' ') for i,l in enumerate(f)]\n",
    "\n",
    "vecs = [d2v.infer_vector(s) for s in foo]\n",
    "\n",
    "squareform(pdist(np.array(vecs), 'cosine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a deep learning library designed for efficient training on super large dataset',\n",
       " 'Repository for all the Pearl code that I never wrote.',\n",
       " 'A matrix algebra library for Tensorflow. Written to take advantage of BLAS and GPU accelerated machines',\n",
       " 'A classification algorithm designed for multi-class classification on high-dimensional data',\n",
       " 'This is a nodejs stream utility library, designed for modular use in your node app']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[' '.join(s) for s in foo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.39126802, 0.26274414, 0.18139755, 0.22882877],\n",
       "       [0.39126802, 0.        , 0.40214265, 0.49948562, 0.28766898],\n",
       "       [0.26274414, 0.40214265, 0.        , 0.39020288, 0.36230746],\n",
       "       [0.18139755, 0.49948562, 0.39020288, 0.        , 0.40054336],\n",
       "       [0.22882877, 0.28766898, 0.36230746, 0.40054336, 0.        ]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_vector(s):\n",
    "    try:\n",
    "        return d2v.wv.get_vector(s)\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "avg_vecs = [np.array([get_vector(s) for s in sent if get_vector(s) is not None]).mean(0) for sent in foo]\n",
    "\n",
    "squareform(pdist(avg_vecs, 'cosine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7772465 , 0.76168656, 0.97259724, 1.0599113 , 0.9560096 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v.wv.distances('javascript', ['python', 'java', 'matlab', 'stata', 'spss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v.save('d2v-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Supervised fastText models are not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-fc2f1c775d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_fasttext_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ft/fasttext-model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36mload_fasttext_format\u001b[0;34m(cls, model_file, encoding)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mmodel_file\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.bin'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_binary_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36mload_binary_data\u001b[0;34m(self, encoding)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36m_load_dict\u001b[0;34m(self, file_handle, encoding)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;31m# Vocab stored by [Dictionary::save](https://github.com/facebookresearch/fastText/blob/master/src/dictionary.cc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnlabels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Supervised fastText models are not supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading %s words for fastText model from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Supervised fastText models are not supported"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "ft = FastText(size=100, min_count=10, window=10, sg=1, epochs=5, workers=7)\n",
    "\n",
    "ft.build_vocab(by_repo_doc)\n",
    "ft.train(by_repo_doc, total_examples=ft.corpus_count, epochs=ft.epochs)\n",
    "ft.save('ft/2/ft2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "embeddings.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
