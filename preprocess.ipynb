{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --quiet tqdm\n",
    "# ! pip install --quiet gcsfs\n",
    "# ! pip install --quiet s3fs\n",
    "! pip install --quiet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from lib.preprocess import *\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from multiprocessing import Pool\n",
    "import threading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "import gcsfs\n",
    "import s3fs\n",
    "from os.path import join\n",
    "import re\n",
    "\n",
    "\n",
    "class ParallelProcessor():    \n",
    "    jl_pattern = re.compile('.+\\.jl$')\n",
    "    csv_pattern = re.compile('.+\\.csv$')\n",
    "\n",
    "    def __init__(self, \n",
    "                 string_processor, \n",
    "                 inpath, \n",
    "                 outpath, \n",
    "                 content_key,                 \n",
    "                 id_key,\n",
    "                 pandas_kwargs = {},\n",
    "                 cores = None,\n",
    "                 fs = gcsfs.GCSFileSystem(project='open-source-software')):\n",
    "        self.string_processor = string_processor\n",
    "        self.inpath = inpath\n",
    "        self.outpath = outpath\n",
    "        self.id_key = id_key\n",
    "        self.content_key = content_key\n",
    "        self.pandas_kwargs = pandas_kwargs\n",
    "        self.cores = cores\n",
    "        self.fs = fs\n",
    "        \n",
    "    def _read_df(self, filename, file):\n",
    "        if re.match(self.csv_pattern, filename):\n",
    "            return pd.read_csv(file, **self.pandas_kwargs)\n",
    "        elif re.match(self.jl_pattern, filename):\n",
    "            return pd.read_json(file, lines=True, **self.pandas_kwargs)\n",
    "        else:\n",
    "             raise TypeError('Cannot parse file: {}'.format(filename))\n",
    "\n",
    "    def _read(self, filename):\n",
    "        with self.fs.open(join(self.inpath, filename)) as fi:            \n",
    "            return self._read_df(filename, fi)\n",
    "            \n",
    "    def _get_files(self):\n",
    "        files = self.fs.ls(self.inpath)\n",
    "        files = [f.split('/')[-1] for f in files]\n",
    "        return [f for f in files if f]\n",
    "    \n",
    "    def process(self,  \n",
    "                       f,  \n",
    "                       compression = 'gzip'):\n",
    "        \n",
    "        key = self.content_key\n",
    "        df = self._read(f)    \n",
    "        df = df[df[key].notna()].reset_index(drop=True)\n",
    "        \n",
    "        processed = df[key].map(self.string_processor)\n",
    "        \n",
    "        df['content'] = processed\n",
    "        df = (df[(df.content.notna()) & (df[self.id_key].notna())]\n",
    "              .reset_index(drop=True)\n",
    "              .drop(key, 1))\n",
    "    \n",
    "        return df\n",
    "        \n",
    "    def process_all(self):\n",
    "        files = self._get_files()\n",
    "        pool = Pool(self.cores)\n",
    "        conn = dataset.connect('sqlite:///{}'.format(self.outpath))\n",
    "        table = conn['processed']        \n",
    "        for df in tqdm_notebook(pool.imap(self.process, files), total=len(files)):\n",
    "            for i,c in zip(df[self.id_key], df.content):\n",
    "                table.insert_ignore({self.id_key: i, 'content': c}, [self.id_key])           \n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9855b720614c499c6842ebfba57124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inpath = 'oecd-scraping/indeed-uk'\n",
    "string_processor = Preprocessor(claims_processor, 4).process\n",
    "p = ParallelProcessor(string_processor, inpath, 'jobs-lookup.db', 'description', 'url', cores=2, fs = s3fs.S3FileSystem())\n",
    "p.process_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e1f6b88e8f468bbdb9e4b8d290f81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=586), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inpath = 'gs://oss_bigquery_exports/patent-descriptions'\n",
    "string_processor = Preprocessor(claims_processor, 4).process\n",
    "p = ParallelProcessor(string_processor, inpath, 'patent-lookup.csv', pandas_kwargs = {'compression':'gzip'}, cores=24)\n",
    "p.process_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess('claims_lookup.csv',  'oss_bigquery_exports/patent-descriptions', \n",
    "#                                                    process_claims, \n",
    "#                                                    'application_number_formatted', 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53dc9103eb514d3e8122d3fa7049b7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preprocess('readme_lookup.csv', 'oss_bigquery_exports/readmes', process_readmes, 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat owner like collaborative filtering? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "by_owner = df.groupby('repo_owner').apply(lambda df: ' \\t '.join(df.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "with open('by_owner.txt', 'w') as f:\n",
    "    for c in by_owner:\n",
    "        f.write(c + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "metric.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
